{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Baseline MNIST Classifier\n",
    "\n",
    "**Objective:** Implement and train a fully-connected neural network for\n",
    "MNIST digit classification.\n",
    "\n",
    "**Implementation:** 5-layer fully-connected network\n",
    "(784→1024→1024→1024→1024→1024→10) with ReLU activations, dropout (0.2),\n",
    "and CrossEntropyLoss. Trained for 50 epochs using Adam optimizer\n",
    "(lr=0.001) on MNIST dataset.\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    import torchvision\n",
    "    import torchvision.transforms as transforms\n",
    "    from torch.utils.data import DataLoader\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    class BaselineMNISTClassifier(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(BaselineMNISTClassifier, self).__init__()\n",
    "            self.fc1 = nn.Linear(28*28, 1024)\n",
    "            self.fc2 = nn.Linear(1024, 1024)\n",
    "            self.fc3 = nn.Linear(1024, 1024)\n",
    "            self.fc4 = nn.Linear(1024, 1024)\n",
    "            self.fc5 = nn.Linear(1024, 1024)\n",
    "            self.out = nn.Linear(1024, 10)\n",
    "            self.dropout = nn.Dropout(0.2)\n",
    "            \n",
    "        def forward(self, x):\n",
    "            x = x.view(-1, 28*28)\n",
    "            x = self.dropout(torch.relu(self.fc1(x)))\n",
    "            x = self.dropout(torch.relu(self.fc2(x)))\n",
    "            x = self.dropout(torch.relu(self.fc3(x)))\n",
    "            x = self.dropout(torch.relu(self.fc4(x)))\n",
    "            x = self.dropout(torch.relu(self.fc5(x)))\n",
    "            x = self.out(x)\n",
    "            return x\n",
    "\n",
    "In \\[4\\]:\n",
    "\n",
    "\n",
    "    class CompressedMNISTClassifier(nn.Module):\n",
    "        def __init__(self, baseline_model, D):\n",
    "            super(CompressedMNISTClassifier, self).__init__()\n",
    "            self.D = D\n",
    "            self.compressed_layers = []\n",
    "            self.biases = []\n",
    "        # compress all layers except the last one\n",
    "            layers_to_compress = [\n",
    "                baseline_model.fc1, baseline_model.fc2, baseline_model.fc3,\n",
    "                baseline_model.fc4, baseline_model.fc5]\n",
    "            \n",
    "            for i, layer in enumerate(layers_to_compress):\n",
    "                U, S, V = torch.svd(layer.weight.data) #svd here\n",
    "                d = min(self.D, len(S))\n",
    "                \n",
    "        # store the compressed weights\n",
    "                U_compressed = U[:, :d]\n",
    "                S_compressed = S[:d]\n",
    "                V_compressed = V[:, :d]\n",
    "                self.compressed_layers.append((U_compressed, S_compressed, V_compressed))\n",
    "                self.biases.append(layer.bias.data)\n",
    "            \n",
    "            # the last layer without compression\n",
    "            self.out_weight = baseline_model.out.weight.data\n",
    "            self.out_bias = baseline_model.out.bias.data\n",
    "        def forward(self, x):\n",
    "            x = x.view(-1, 28*28)\n",
    "            for i in range(len(self.compressed_layers)):\n",
    "                U, S, V = self.compressed_layers[i]\n",
    "                W_approx = torch.mm(torch.mm(U, torch.diag(S)), V.t())\n",
    "                x = torch.relu(torch.mm(x, W_approx.t()) + self.biases[i])\n",
    "                if self.training:\n",
    "                    x = torch.dropout(x, p=0.5, train=True)\n",
    "            # final layer\n",
    "            x = torch.mm(x, self.out_weight.t()) + self.out_bias\n",
    "            return x\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    def count_parameters(model, compressed=False, D=None):\n",
    "        if not compressed:\n",
    "            return sum(p.numel() for p in model.parameters())\n",
    "        else:\n",
    "            total_params = 0\n",
    "            total_params += 784 * D + D + 1024 * D  # U + S + V #D non zero parameters\n",
    "            total_params += 4 * (1024 * D + D + 1024 * D)  # 4 layers\n",
    "            # Last layer\n",
    "            total_params += 1024 * 10 + 10  # Uncompressed\n",
    "            # Biases\n",
    "            total_params += 5 * 1024 + 10\n",
    "            return total_params\n",
    "\n",
    "In \\[6\\]:\n",
    "\n",
    "    def train(model, train_loader, test_loader, epochs, device):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        \n",
    "        train_losses = []\n",
    "        test_accuracies = []\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                \n",
    "            # Evaluate\n",
    "            model.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for images, labels in test_loader:\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    outputs = model(images)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            accuracy = 100 * correct / total\n",
    "            print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}, Accuracy: {accuracy:.2f}%')\n",
    "            \n",
    "            train_losses.append(running_loss/len(train_loader))\n",
    "            test_accuracies.append(accuracy)\n",
    "        \n",
    "        return train_losses, test_accuracies\n",
    "\n",
    "In \\[13\\]:\n",
    "\n",
    "    def main():\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        train_dataset = torchvision.datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "        test_dataset = torchvision.datasets.MNIST('./data', train=False, transform=transform)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=128, shuffle=True)\n",
    "        \n",
    "        print(\"Training baseline model...\")\n",
    "        baseline_model = BaselineMNISTClassifier().to(device)\n",
    "        baseline_losses, baseline_accuracies = train(baseline_model, train_loader, test_loader, epochs=50, device=device)\n",
    "        \n",
    "        baseline_params = count_parameters(baseline_model)\n",
    "        print(f\"\\nBaseline model parameters: {baseline_params:,}\")\n",
    "\n",
    "        print(f\"\\nBaseline model Saved:\", )\n",
    "        torch.save(baseline_model.state_dict(), \"mnist_baseline.pth\")\n",
    "\n",
    "\n",
    "        D_values = [10, 20, 50, 100, 200, 1024]\n",
    "        compression_results = []\n",
    "\n",
    "        for D in D_values:\n",
    "            print(f\"\\nTesting compression with D={D}\")\n",
    "\n",
    "            compressed_model = CompressedMNISTClassifier(baseline_model, D).to(device)\n",
    "            compressed_params = count_parameters(compressed_model, compressed=True, D=D)\n",
    "\n",
    "\n",
    "            # Evaluate compressed model\n",
    "            compressed_model.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for images, labels in test_loader:\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    outputs = compressed_model(images)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            accuracy = 100 * correct / total\n",
    "            compression_ratio = baseline_params / compressed_params\n",
    "            \n",
    "            print(f\"D={D}:\")\n",
    "            print(f\"Parameters: {compressed_params:,}\")\n",
    "            print(f\"Compression ratio: {compression_ratio:.2f}x\")\n",
    "            print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "            \n",
    "            compression_results.append({\n",
    "                'D': D,\n",
    "                'params': compressed_params,\n",
    "                'ratio': compression_ratio,\n",
    "                'accuracy': accuracy\n",
    "            })\n",
    "        \n",
    "        # plot results\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot([r['D'] for r in compression_results], \n",
    "                 [r['accuracy'] for r in compression_results], \n",
    "                 'bo-')\n",
    "        plt.xlabel('D (Number of singular values)')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.title('Accuracy vs Compression Level')\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot([r['D'] for r in compression_results], \n",
    "                 [r['ratio'] for r in compression_results], \n",
    "                 'ro-')\n",
    "        plt.xlabel('D (Number of singular values)')\n",
    "        plt.ylabel('Compression Ratio')\n",
    "        plt.title('Compression Ratio vs D')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    if __name__ == '__main__':\n",
    "        main()\n",
    "\n",
    "    Training baseline model...\n",
    "    Epoch 1, Loss: 0.2964, Accuracy: 96.37%\n",
    "    Epoch 2, Loss: 0.1475, Accuracy: 97.55%\n",
    "    Epoch 3, Loss: 0.1181, Accuracy: 97.36%\n",
    "    Epoch 4, Loss: 0.0977, Accuracy: 96.91%\n",
    "    Epoch 5, Loss: 0.0900, Accuracy: 97.61%\n",
    "    Epoch 6, Loss: 0.0810, Accuracy: 97.80%\n",
    "    Epoch 7, Loss: 0.0706, Accuracy: 97.93%\n",
    "    Epoch 8, Loss: 0.0712, Accuracy: 97.83%\n",
    "    Epoch 9, Loss: 0.0689, Accuracy: 98.23%\n",
    "    Epoch 10, Loss: 0.0546, Accuracy: 98.10%\n",
    "    Epoch 11, Loss: 0.0537, Accuracy: 98.17%\n",
    "    Epoch 12, Loss: 0.0532, Accuracy: 98.01%\n",
    "    Epoch 13, Loss: 0.0525, Accuracy: 98.01%\n",
    "    Epoch 14, Loss: 0.0472, Accuracy: 98.08%\n",
    "    Epoch 15, Loss: 0.0469, Accuracy: 98.08%\n",
    "    Epoch 16, Loss: 0.0457, Accuracy: 98.21%\n",
    "    Epoch 17, Loss: 0.0470, Accuracy: 98.16%\n",
    "    Epoch 18, Loss: 0.0461, Accuracy: 98.30%\n",
    "    Epoch 19, Loss: 0.0454, Accuracy: 98.54%\n",
    "    Epoch 20, Loss: 0.0379, Accuracy: 98.20%\n",
    "    Epoch 21, Loss: 0.0422, Accuracy: 98.34%\n",
    "    Epoch 22, Loss: 0.0400, Accuracy: 98.24%\n",
    "    Epoch 23, Loss: 0.0464, Accuracy: 98.05%\n",
    "    Epoch 24, Loss: 0.0421, Accuracy: 98.16%\n",
    "    Epoch 25, Loss: 0.0386, Accuracy: 98.54%\n",
    "    Epoch 26, Loss: 0.0332, Accuracy: 98.25%\n",
    "    Epoch 27, Loss: 0.0414, Accuracy: 98.19%\n",
    "    Epoch 28, Loss: 0.0410, Accuracy: 98.35%\n",
    "    Epoch 29, Loss: 0.0315, Accuracy: 97.99%\n",
    "    Epoch 30, Loss: 0.0366, Accuracy: 98.21%\n",
    "    Epoch 31, Loss: 0.0352, Accuracy: 98.40%\n",
    "    Epoch 32, Loss: 0.0387, Accuracy: 98.40%\n",
    "    Epoch 33, Loss: 0.0390, Accuracy: 98.21%\n",
    "    Epoch 34, Loss: 0.0362, Accuracy: 98.40%\n",
    "    Epoch 35, Loss: 0.0526, Accuracy: 98.31%\n",
    "    Epoch 36, Loss: 0.0293, Accuracy: 98.38%\n",
    "    Epoch 37, Loss: 0.0280, Accuracy: 98.34%\n",
    "    Epoch 38, Loss: 0.0328, Accuracy: 98.37%\n",
    "    Epoch 39, Loss: 0.0327, Accuracy: 98.35%\n",
    "    Epoch 40, Loss: 0.0347, Accuracy: 98.35%\n",
    "    Epoch 41, Loss: 0.0303, Accuracy: 98.16%\n",
    "    Epoch 42, Loss: 0.0326, Accuracy: 98.39%\n",
    "    Epoch 43, Loss: 0.0291, Accuracy: 98.49%\n",
    "    Epoch 44, Loss: 0.0332, Accuracy: 98.32%\n",
    "    Epoch 45, Loss: 0.0381, Accuracy: 98.42%\n",
    "    Epoch 46, Loss: 0.0335, Accuracy: 98.49%\n",
    "    Epoch 47, Loss: 0.0339, Accuracy: 98.30%\n",
    "    Epoch 48, Loss: 0.0320, Accuracy: 98.47%\n",
    "    Epoch 49, Loss: 0.0225, Accuracy: 98.54%\n",
    "    Epoch 50, Loss: 0.0311, Accuracy: 98.44%\n",
    "\n",
    "    Baseline model parameters: 5,012,490\n",
    "\n",
    "    Baseline model Saved:\n",
    "\n",
    "    Testing compression with D=10\n",
    "    D=10:\n",
    "    Parameters: 115,430\n",
    "    Compression ratio: 43.42x\n",
    "    Accuracy: 27.92%\n",
    "\n",
    "    Testing compression with D=20\n",
    "    D=20:\n",
    "    Parameters: 215,480\n",
    "    Compression ratio: 23.26x\n",
    "    Accuracy: 71.90%\n",
    "\n",
    "    Testing compression with D=50\n",
    "    D=50:\n",
    "    Parameters: 515,630\n",
    "    Compression ratio: 9.72x\n",
    "    Accuracy: 93.44%\n",
    "\n",
    "    Testing compression with D=100\n",
    "    D=100:\n",
    "    Parameters: 1,015,880\n",
    "    Compression ratio: 4.93x\n",
    "    Accuracy: 97.88%\n",
    "\n",
    "    Testing compression with D=200\n",
    "    D=200:\n",
    "    Parameters: 2,016,380\n",
    "    Compression ratio: 2.49x\n",
    "    Accuracy: 98.40%\n",
    "\n",
    "    Testing compression with D=1024\n",
    "    D=1024:\n",
    "    Parameters: 10,260,500\n",
    "    Compression ratio: 0.49x\n",
    "    Accuracy: 98.44%\n",
    "\n",
    "Question 2\n",
    "\n",
    "## Question 2: Model Compression via Low-Rank Factorization\n",
    "\n",
    "**Objective:** Compress the trained baseline model using low-rank\n",
    "factorization (W ≈ UV^T) and evaluate accuracy vs. compression\n",
    "trade-offs.\n",
    "\n",
    "**Implementation:** Factorizes fully-connected layers into U, V matrices\n",
    "with rank D. Tests compression levels (D=10, 20, 50, 100, 200, 1024) and\n",
    "analyzes parameter count reduction vs. accuracy. Initializes compressed\n",
    "weights from SVD decomposition of original weights.\n",
    "\n",
    "In \\[14\\]:\n",
    "\n",
    "    import torch.nn.functional as F\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "    baseline_model = BaselineMNISTClassifier().to(device)\n",
    "    baseline_model.load_state_dict(torch.load(\"mnist_baseline.pth\", weights_only=True))\n",
    "\n",
    "Out\\[14\\]:\n",
    "\n",
    "    <All keys matched successfully>\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    class FactorizedLinear(nn.Module):\n",
    "        def __init__(self, in_features, out_features, D=20):\n",
    "            super(FactorizedLinear, self).__init__()\n",
    "            self.in_features = in_features\n",
    "            self.out_features = out_features\n",
    "            self.D = D\n",
    "\n",
    "            # initialize U and V matrices\n",
    "            self.U = nn.Parameter(torch.randn(out_features, D))\n",
    "            self.V = nn.Parameter(torch.randn(in_features, D))\n",
    "            self.bias = nn.Parameter(torch.zeros(out_features))\n",
    "            \n",
    "        def forward(self, x):\n",
    "            return F.linear(x, torch.mm(self.U, self.V.t()), self.bias)\n",
    "        \n",
    "        def initialize_from_svd(self, U_svd, S_svd, V_svd):\n",
    "\n",
    "            with torch.no_grad():\n",
    "                self.U.data.copy_(U_svd[:, :self.D])\n",
    "                self.V.data.copy_(torch.mm(V_svd[:, :self.D], torch.diag(S_svd[:self.D])))\n",
    "\n",
    "\n",
    "    class FactorizedMNISTClassifier(nn.Module):\n",
    "        def __init__(self, D=20):\n",
    "            super(FactorizedMNISTClassifier, self).__init__()\n",
    "            self.fc1 = FactorizedLinear(28*28, 1024, D)\n",
    "            self.fc2 = FactorizedLinear(1024, 1024, D)\n",
    "            self.fc3 = FactorizedLinear(1024, 1024, D)\n",
    "            self.fc4 = FactorizedLinear(1024, 1024, D)\n",
    "            self.fc5 = FactorizedLinear(1024, 1024, D)\n",
    "            self.out = nn.Linear(1024, 10)  # Last layer remains unfactorized\n",
    "            self.dropout = nn.Dropout(0.5)\n",
    "            \n",
    "        def forward(self, x):\n",
    "            x = x.view(-1, 28*28)\n",
    "            x = self.dropout(torch.relu(self.fc1(x)))\n",
    "            x = self.dropout(torch.relu(self.fc2(x)))\n",
    "            x = self.dropout(torch.relu(self.fc3(x)))\n",
    "            x = self.dropout(torch.relu(self.fc4(x)))\n",
    "            x = self.dropout(torch.relu(self.fc5(x)))\n",
    "            x = self.out(x)\n",
    "            return x\n",
    "        \n",
    "        def initialize_from_baseline(self, baseline_model):\n",
    "\n",
    "            #Initialize factorized layers using SVD results from baseline model\n",
    "            \n",
    "            U, S, V = torch.svd(baseline_model.fc1.weight.data)\n",
    "            self.fc1.initialize_from_svd(U, S, V)\n",
    "            self.fc1.bias.data.copy_(baseline_model.fc1.bias.data)\n",
    "            U, S, V = torch.svd(baseline_model.fc2.weight.data)\n",
    "            self.fc2.initialize_from_svd(U, S, V)\n",
    "            self.fc2.bias.data.copy_(baseline_model.fc2.bias.data)\n",
    "            U, S, V = torch.svd(baseline_model.fc3.weight.data)\n",
    "            self.fc3.initialize_from_svd(U, S, V)\n",
    "            self.fc3.bias.data.copy_(baseline_model.fc3.bias.data)\n",
    "            U, S, V = torch.svd(baseline_model.fc4.weight.data)\n",
    "            self.fc4.initialize_from_svd(U, S, V)\n",
    "            self.fc4.bias.data.copy_(baseline_model.fc4.bias.data)\n",
    "            U, S, V = torch.svd(baseline_model.fc5.weight.data)\n",
    "            self.fc5.initialize_from_svd(U, S, V)\n",
    "            self.fc5.bias.data.copy_(baseline_model.fc5.bias.data)\n",
    "            self.out.weight.data.copy_(baseline_model.out.weight.data)\n",
    "            self.out.bias.data.copy_(baseline_model.out.bias.data)\n",
    "\n",
    "In \\[16\\]:\n",
    "\n",
    "    def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = 100 * correct / total\n",
    "        return epoch_loss, epoch_acc\n",
    "\n",
    "    def evaluate(model, test_loader, device):\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        accuracy = 100 * correct / total\n",
    "        return accuracy\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    import torch.optim as optim\n",
    "    from torchvision import datasets, transforms\n",
    "    from torch.utils.data import DataLoader\n",
    "    import torch.nn.functional as F\n",
    "\n",
    "In \\[19\\]:\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "    test_dataset = datasets.MNIST(root='./data', train=False, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "In \\[21\\]:\n",
    "\n",
    "    def main():\n",
    "        factorized_model = FactorizedMNISTClassifier(D=20).to(device)\n",
    "        factorized_model.initialize_from_baseline(baseline_model)\n",
    "        initial_accuracy = evaluate(factorized_model, test_loader, device) # Initial evaluation\n",
    "\n",
    "        print(f\"Initial test accuracy (before finetuning) for D=20: {initial_accuracy:.2f}%\")\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss() # Finetuning\n",
    "        optimizer = optim.Adam(factorized_model.parameters(), lr=0.0001)  # Smaller learning rate for finetuning\n",
    "        \n",
    "        \n",
    "        print(\"\\nFinetuning factorized model 1...2...3... Go...\")\n",
    "        for epoch in range(20):\n",
    "            loss, acc = train_epoch(factorized_model, train_loader, criterion, optimizer, device)\n",
    "            test_acc = evaluate(factorized_model, test_loader, device)\n",
    "            print(f\"Finetuning - Epoch {epoch+1}: Train Loss = {loss:.4f}, Train Acc = {acc:.2f}%, Test Acc = {test_acc:.2f}%\")\n",
    "\n",
    "    #run main    \n",
    "    if __name__ == \"__main__\":\n",
    "        main()\n",
    "\n",
    "    Initial test accuracy (before finetuning) for D=20: 71.90%\n",
    "\n",
    "    Finetuning factorized model 1...2...3... Go...\n",
    "    Finetuning - Epoch 1: Train Loss = 0.3414, Train Acc = 92.51%, Test Acc = 97.22%\n",
    "    Finetuning - Epoch 2: Train Loss = 0.2323, Train Acc = 95.13%, Test Acc = 97.45%\n",
    "    Finetuning - Epoch 3: Train Loss = 0.1976, Train Acc = 95.55%, Test Acc = 97.59%\n",
    "    Finetuning - Epoch 4: Train Loss = 0.1702, Train Acc = 96.07%, Test Acc = 97.54%\n",
    "    Finetuning - Epoch 5: Train Loss = 0.1595, Train Acc = 96.27%, Test Acc = 97.63%\n",
    "    Finetuning - Epoch 6: Train Loss = 0.1558, Train Acc = 96.51%, Test Acc = 97.70%\n",
    "    Finetuning - Epoch 7: Train Loss = 0.1403, Train Acc = 96.66%, Test Acc = 97.88%\n",
    "    Finetuning - Epoch 8: Train Loss = 0.1331, Train Acc = 96.94%, Test Acc = 97.76%\n",
    "    Finetuning - Epoch 9: Train Loss = 0.1307, Train Acc = 96.82%, Test Acc = 97.73%\n",
    "    Finetuning - Epoch 10: Train Loss = 0.1663, Train Acc = 97.07%, Test Acc = 97.81%\n",
    "    Finetuning - Epoch 11: Train Loss = 0.1189, Train Acc = 97.11%, Test Acc = 97.93%\n",
    "    Finetuning - Epoch 12: Train Loss = 0.1170, Train Acc = 97.16%, Test Acc = 97.85%\n",
    "    Finetuning - Epoch 13: Train Loss = 0.1131, Train Acc = 97.24%, Test Acc = 97.98%\n",
    "    Finetuning - Epoch 14: Train Loss = 0.1088, Train Acc = 97.30%, Test Acc = 97.98%\n",
    "    Finetuning - Epoch 15: Train Loss = 0.1086, Train Acc = 97.29%, Test Acc = 98.00%\n",
    "    Finetuning - Epoch 16: Train Loss = 0.1072, Train Acc = 97.36%, Test Acc = 97.91%\n",
    "    Finetuning - Epoch 17: Train Loss = 0.1105, Train Acc = 97.30%, Test Acc = 97.91%\n",
    "    Finetuning - Epoch 18: Train Loss = 0.1002, Train Acc = 97.60%, Test Acc = 97.95%\n",
    "    Finetuning - Epoch 19: Train Loss = 0.0993, Train Acc = 97.51%, Test Acc = 97.94%\n",
    "    Finetuning - Epoch 20: Train Loss = 0.0977, Train Acc = 97.62%, Test Acc = 97.93%\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    epochs = list(range(1, 21))\n",
    "    train_loss = [0.3414, 0.2323, 0.1976, 0.1702, 0.1595, 0.1558, 0.1403, 0.1331, 0.1307, 0.1663, \n",
    "                  0.1189, 0.1170, 0.1131, 0.1088, 0.1086, 0.1072, 0.1105, 0.1002, 0.0993, 0.0977]\n",
    "    test_accuracy = [97.22, 97.45, 97.59, 97.54, 97.63, 97.70, 97.88, 97.76, 97.73, 97.81, \n",
    "                     97.93, 97.85, 97.98, 97.98, 98.00, 97.91, 97.91, 97.95, 97.94, 97.93]\n",
    "\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_loss, label='Training Loss', marker='o', color='blue')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss Over Epochs')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "\n",
    "    plt.plot(epochs, test_accuracy, label='Test Accuracy', marker='o', color='red')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Test Accuracy Over Epochs')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "## Question 3: Training Compressed Models from Scratch\n",
    "\n",
    "**Objective:** Train compressed models (using SVD factorization) from\n",
    "scratch rather than initializing from pre-trained weights, and compare\n",
    "training dynamics and final accuracy.\n",
    "\n",
    "**Implementation:** Creates SVDCompressedNet architecture with low-rank\n",
    "factorization applied during training. Trains models with different\n",
    "compression ranks (D) from scratch using dropout (0.5), comparing\n",
    "convergence behavior and accuracy against compressed models initialized\n",
    "from Q1 baseline.\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    from torchvision import datasets, transforms\n",
    "    from torch.utils.data import DataLoader\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "    train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    test_dataset = datasets.MNIST(root='./data', train=False, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    class BaselineMNISTClassifier(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(BaselineMNISTClassifier, self).__init__()\n",
    "            self.fc1 = nn.Linear(28*28, 1024)\n",
    "            self.fc2 = nn.Linear(1024, 1024)\n",
    "            self.fc3 = nn.Linear(1024, 1024)\n",
    "            self.fc4 = nn.Linear(1024, 1024)\n",
    "            self.fc5 = nn.Linear(1024, 1024)\n",
    "            self.out = nn.Linear(1024, 10)\n",
    "            self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = x.view(-1, 28*28)\n",
    "            x = self.dropout(torch.relu(self.fc1(x)))\n",
    "            x = self.dropout(torch.relu(self.fc2(x)))\n",
    "            x = self.dropout(torch.relu(self.fc3(x)))\n",
    "            x = self.dropout(torch.relu(self.fc4(x)))\n",
    "            x = self.dropout(torch.relu(self.fc5(x)))\n",
    "            x = self.out(x)\n",
    "            return x\n",
    "\n",
    "    class SVDCompressedNet(nn.Module):\n",
    "        def __init__(self, D=20):\n",
    "            super(SVDCompressedNet, self).__init__()\n",
    "            self.D = D\n",
    "            self.fc1 = nn.Linear(28*28, 1024)\n",
    "            self.fc2 = nn.Linear(1024, 1024)\n",
    "            self.fc3 = nn.Linear(1024, 1024)\n",
    "            self.fc4 = nn.Linear(1024, 1024)\n",
    "            self.fc5 = nn.Linear(1024, 1024)\n",
    "            self.out = nn.Linear(1024, 10)\n",
    "            self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        def svd_compress(self, weight):\n",
    "            U, S, V = torch.svd(weight)\n",
    "            return U[:, :self.D] @ torch.diag(S[:self.D]) @ V.t()[:self.D, :]\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = x.view(-1, 28*28)\n",
    "            #do svd for every forward step\n",
    "            x = self.dropout(torch.relu(self.svd_compress(self.fc1.weight) @ x.t() + self.fc1.bias.unsqueeze(1))).t() \n",
    "            x = self.dropout(torch.relu(self.svd_compress(self.fc2.weight) @ x.t() + self.fc2.bias.unsqueeze(1))).t()\n",
    "            x = self.dropout(torch.relu(self.svd_compress(self.fc3.weight) @ x.t() + self.fc3.bias.unsqueeze(1))).t()\n",
    "            x = self.dropout(torch.relu(self.svd_compress(self.fc4.weight) @ x.t() + self.fc4.bias.unsqueeze(1))).t()\n",
    "            x = self.dropout(torch.relu(self.svd_compress(self.fc5.weight) @ x.t() + self.fc5.bias.unsqueeze(1))).t()\n",
    "            x = self.out(x)  # last layer remains uncompressed\n",
    "            return x\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    model = SVDCompressedNet().to(device)\n",
    "    baseline_model = BaselineMNISTClassifier()\n",
    "    baseline_model.load_state_dict(torch.load('mnist_baseline.pth', weights_only=True))\n",
    "    model.load_state_dict(baseline_model.state_dict())\n",
    "\n",
    "    <All keys matched successfully>\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    # Training function\n",
    "    def train(model, train_loader, optimizer, criterion, device):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    def test(model, test_loader, device):\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        return correct / len(test_loader.dataset)\n",
    "\n",
    "    # loop\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)  # Using a small learning rate here\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    #train - Took me forever this\n",
    "    num_epochs = 10\n",
    "    for epoch in range(num_epochs):\n",
    "        train(model, train_loader, optimizer, criterion, device)\n",
    "        accuracy = test(model, test_loader, device)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Final evaluation\n",
    "    final_accuracy = test(model, test_loader, device)\n",
    "    print(f\"Final Test Accuracy: {final_accuracy:.4f}\")\n",
    "\n",
    "    # Calculate compression ratio\n",
    "    def count_parameters(model):\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    baseline_params = count_parameters(baseline_model)\n",
    "    compressed_params = count_parameters(model)\n",
    "\n",
    "    Epoch 1/10, Test Accuracy: 0.9720\n",
    "    Epoch 2/10, Test Accuracy: 0.9750\n",
    "    Epoch 3/10, Test Accuracy: 0.9764\n",
    "    Epoch 4/10, Test Accuracy: 0.9777\n",
    "    Epoch 5/10, Test Accuracy: 0.9774\n",
    "    Epoch 6/10, Test Accuracy: 0.9771\n",
    "    Epoch 7/10, Test Accuracy: 0.9776\n",
    "    Epoch 8/10, Test Accuracy: 0.9789\n",
    "    Epoch 9/10, Test Accuracy: 0.9787\n",
    "    Epoch 10/10, Test Accuracy: 0.9795\n",
    "    Final Test Accuracy: 0.9795\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    epochs = list(range(1, 11))\n",
    "    test_accuracy = [0.9720, 0.9750, 0.9764, 0.9777, 0.9774, 0.9771, 0.9776, 0.9789, 0.9787, 0.9795] #have taken the values from above\n",
    "    test_accuracy = [acc * 100 for acc in test_accuracy] #for better interpretibility\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, test_accuracy, marker='o', linestyle='-', color='b')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Test Accuracy')\n",
    "    plt.title('Test Accuracy Over Epochs')\n",
    "    plt.xticks(epochs)\n",
    "    plt.grid(True)\n",
    "    plt.annotate(f'Final: {test_accuracy[-1]:.4f}', \n",
    "                 xy=(epochs[-1], test_accuracy[-1]), \n",
    "                 xytext=(epochs[-1] - 1, test_accuracy[-1] - 0.002),\n",
    "                 arrowprops=dict(facecolor='black', arrowstyle='->'),\n",
    "                 fontsize=10)\n",
    "    plt.show()\n",
    "\n",
    "## Question 4: Speaker Recognition with Siamese Networks\n",
    "\n",
    "**Objective:** Implement speaker recognition using a Siamese network\n",
    "architecture with GRU encoder and cosine similarity-based verification.\n",
    "\n",
    "**Implementation:** SpeakerEncoder with bidirectional GRU\n",
    "(input_size=513, hidden_size=256, 2 layers) processes audio\n",
    "spectrograms. SiameseNetwork computes L2-normalized embeddings and\n",
    "cosine similarity between pairs. Trained on speaker verification task\n",
    "(same/different speaker classification) using contrastive loss.\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    import librosa\n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "    import itertools\n",
    "    import random\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    class SpeakerEncoder(nn.Module):\n",
    "        def __init__(self, input_size=513, hidden_size=256, num_layers=2):\n",
    "            super(SpeakerEncoder, self).__init__()\n",
    "            self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "            self.fc = nn.Linear(hidden_size * 2, hidden_size)\n",
    "\n",
    "        def forward(self, x):\n",
    "            output, hidden = self.gru(x)\n",
    "            hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
    "            embedding = self.fc(hidden)\n",
    "            embedding = torch.nn.functional.normalize(embedding, p=2, dim=1)\n",
    "            return embedding\n",
    "\n",
    "    #siamese network\n",
    "    class SiameseNetwork(nn.Module):\n",
    "        def __init__(self, encoder):\n",
    "            super(SiameseNetwork, self).__init__()\n",
    "            self.encoder = encoder\n",
    "            \n",
    "        def forward(self, x1, x2):\n",
    "            embedding1 = self.encoder(x1)\n",
    "            embedding2 = self.encoder(x2)\n",
    "            similarity = torch.sum(embedding1 * embedding2, dim=1, keepdim=True)\n",
    "            output = torch.sigmoid(similarity)\n",
    "            return output\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    class SpeakerPairDataset(Dataset):\n",
    "        def __init__(self, data, L, speaker_idx, mode='train'):\n",
    "            self.data = data\n",
    "            self.L = L\n",
    "            self.speaker_idx = speaker_idx\n",
    "            self.mode = mode\n",
    "            self.pairs, self.labels = self._create_pairs()\n",
    "        \n",
    "        def _create_pairs(self):\n",
    "            pairs = []\n",
    "            labels = []\n",
    "            start_idx = self.speaker_idx * 10\n",
    "            speaker_utterances = self.data[start_idx:start_idx + 10]\n",
    "            pos_pairs = list(itertools.combinations(range(10), 2))\n",
    "            if self.L < len(pos_pairs):\n",
    "                pos_pairs = random.sample(pos_pairs, self.L)\n",
    "            for i, j in pos_pairs:\n",
    "                pairs.append((speaker_utterances[i], speaker_utterances[j]))\n",
    "                labels.append(1)\n",
    "            other_speakers = list(range(50 if self.mode == 'train' else 20))\n",
    "            other_speakers.remove(self.speaker_idx)\n",
    "            for _ in range(self.L):\n",
    "                i = random.randint(0, 9)\n",
    "                other_speaker = random.choice(other_speakers)\n",
    "                j = random.randint(0, 9)\n",
    "                other_utterance = self.data[other_speaker * 10 + j]\n",
    "                pairs.append((speaker_utterances[i], other_utterance))\n",
    "                labels.append(0)\n",
    "            return pairs, labels\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.pairs)\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            utterance1, utterance2 = self.pairs[idx]\n",
    "            n_fft = 1024 \n",
    "            hop_length = n_fft // 4\n",
    "            spec1 = np.abs(librosa.stft(utterance1, n_fft=n_fft, hop_length=hop_length))\n",
    "            spec2 = np.abs(librosa.stft(utterance2, n_fft=n_fft, hop_length=hop_length))\n",
    "            assert spec1.shape[0] == 513, f\"Expected 513 frequency bins, got {spec1.shape[0]}\"\n",
    "            spec1 = np.log1p(spec1)\n",
    "            spec2 = np.log1p(spec2)\n",
    "            spec1 = (spec1 - spec1.mean()) / (spec1.std() + 1e-8)\n",
    "            spec2 = (spec2 - spec2.mean()) / (spec2.std() + 1e-8)\n",
    "            \n",
    "            spec1 = torch.FloatTensor(spec1.T)\n",
    "            spec2 = torch.FloatTensor(spec2.T)\n",
    "            label = torch.FloatTensor([self.labels[idx]]).reshape(1)\n",
    "            return spec1, spec2, label\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    def train_model(train_data, test_data, L=10, num_epochs=50):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"Using device: {device}\")\n",
    "        encoder = SpeakerEncoder().to(device)\n",
    "        model = SiameseNetwork(encoder).to(device)\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(model.parameters())\n",
    "        \n",
    "        # Initialize lists to store metrics\n",
    "        train_losses = []\n",
    "        test_losses = []\n",
    "        train_accuracies = []\n",
    "        test_accuracies = []\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "            correct_train = 0\n",
    "            total_train = 0\n",
    "            \n",
    "            # Training loop\n",
    "            for speaker_idx in range(50):\n",
    "                dataset = SpeakerPairDataset(train_data, L, speaker_idx)\n",
    "                dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "                \n",
    "                for batch_idx, (spec1, spec2, labels) in enumerate(dataloader):\n",
    "                    spec1, spec2, labels = spec1.to(device), spec2.to(device), labels.to(device)\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(spec1, spec2)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    total_loss += loss.item()\n",
    "                    \n",
    "                    # Calculate training accuracy\n",
    "                    predicted = (outputs > 0.5).float()\n",
    "                    correct_train += (predicted == labels).sum().item()\n",
    "                    total_train += labels.size(0)\n",
    "            \n",
    "            # Average training loss and accuracy for the epoch\n",
    "            avg_train_loss = total_loss / 50\n",
    "            train_accuracy = 100 * correct_train / total_train\n",
    "            train_losses.append(avg_train_loss)\n",
    "            train_accuracies.append(train_accuracy)\n",
    "            \n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {avg_train_loss:.4f}, Training Accuracy: {train_accuracy:.2f}%')\n",
    "            \n",
    "            model.eval()\n",
    "            total_test_loss = 0\n",
    "            correct_test = 0\n",
    "            total_test = 0\n",
    "            with torch.no_grad():\n",
    "                for speaker_idx in range(20):\n",
    "                    dataset = SpeakerPairDataset(test_data, L, speaker_idx, mode='test')\n",
    "                    dataloader = DataLoader(dataset, batch_size=32)\n",
    "                    \n",
    "                    for spec1, spec2, labels in dataloader:\n",
    "                        spec1, spec2, labels = spec1.to(device), spec2.to(device), labels.to(device)\n",
    "                        outputs = model(spec1, spec2)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        \n",
    "                        total_test_loss += loss.item()\n",
    "                        predicted = (outputs > 0.5).float()\n",
    "                        correct_test += (predicted == labels).sum().item()\n",
    "                        total_test += labels.size(0)\n",
    "            \n",
    "            avg_test_loss = total_test_loss / 20\n",
    "            test_accuracy = 100 * correct_test / total_test\n",
    "            test_losses.append(avg_test_loss)\n",
    "            test_accuracies.append(test_accuracy)\n",
    "            \n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')\n",
    "        \n",
    "        epochs = range(1, num_epochs + 1)\n",
    "        \n",
    "        plt.figure(figsize=(14, 6))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(epochs, train_losses, label='Training Loss', marker='o')\n",
    "        plt.plot(epochs, test_losses, label='Testing Loss', marker='o')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training and Testing Loss Over Epochs')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(epochs, train_accuracies, label='Training Accuracy', marker='o')\n",
    "        plt.plot(epochs, test_accuracies, label='Testing Accuracy', marker='o')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.title('Training and Testing Accuracy Over Epochs')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return model, train_accuracies, test_accuracies, train_losses, test_losses\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "        with open('trs.pkl', 'rb') as f:\n",
    "            train_data = pickle.load(f)\n",
    "        with open('tes.pkl', 'rb') as f:\n",
    "            test_data = pickle.load(f)\n",
    "        model, train_accuracies, test_accuracies, train_losses, test_losses = train_model(train_data, test_data, L=10)\n",
    "\n",
    "    Using device: cuda\n",
    "    Epoch 1/50, Training Loss: 0.7358, Training Accuracy: 51.00%\n",
    "    Epoch 1/50, Test Loss: 0.7345, Test Accuracy: 52.50%\n",
    "    Epoch 2/50, Training Loss: 0.7142, Training Accuracy: 53.60%\n",
    "    Epoch 2/50, Test Loss: 0.7420, Test Accuracy: 50.25%\n",
    "    Epoch 3/50, Training Loss: 0.6997, Training Accuracy: 54.60%\n",
    "    Epoch 3/50, Test Loss: 0.7025, Test Accuracy: 53.25%\n",
    "    Epoch 4/50, Training Loss: 0.6855, Training Accuracy: 56.70%\n",
    "    Epoch 4/50, Test Loss: 0.6601, Test Accuracy: 60.75%\n",
    "    Epoch 5/50, Training Loss: 0.6589, Training Accuracy: 61.50%\n",
    "    Epoch 5/50, Test Loss: 0.6914, Test Accuracy: 60.25%\n",
    "    Epoch 6/50, Training Loss: 0.6954, Training Accuracy: 59.20%\n",
    "    Epoch 6/50, Test Loss: 0.6111, Test Accuracy: 70.00%\n",
    "    Epoch 7/50, Training Loss: 0.6151, Training Accuracy: 67.00%\n",
    "    Epoch 7/50, Test Loss: 0.6430, Test Accuracy: 63.75%\n",
    "    Epoch 8/50, Training Loss: 0.6238, Training Accuracy: 66.70%\n",
    "    Epoch 8/50, Test Loss: 0.6036, Test Accuracy: 70.00%\n",
    "    Epoch 9/50, Training Loss: 0.6123, Training Accuracy: 68.40%\n",
    "    Epoch 9/50, Test Loss: 0.6548, Test Accuracy: 61.75%\n",
    "    Epoch 10/50, Training Loss: 0.6143, Training Accuracy: 68.80%\n",
    "    Epoch 10/50, Test Loss: 0.6003, Test Accuracy: 71.00%\n",
    "    Epoch 11/50, Training Loss: 0.5913, Training Accuracy: 70.40%\n",
    "    Epoch 11/50, Test Loss: 0.6024, Test Accuracy: 69.50%\n",
    "    Epoch 12/50, Training Loss: 0.5699, Training Accuracy: 73.30%\n",
    "    Epoch 12/50, Test Loss: 0.5951, Test Accuracy: 69.75%\n",
    "    Epoch 13/50, Training Loss: 0.5702, Training Accuracy: 73.20%\n",
    "    Epoch 13/50, Test Loss: 0.6089, Test Accuracy: 68.75%\n",
    "    Epoch 14/50, Training Loss: 0.5680, Training Accuracy: 74.50%\n",
    "    Epoch 14/50, Test Loss: 0.5932, Test Accuracy: 73.25%\n",
    "    Epoch 15/50, Training Loss: 0.5630, Training Accuracy: 75.60%\n",
    "    Epoch 15/50, Test Loss: 0.6261, Test Accuracy: 66.00%\n",
    "    Epoch 16/50, Training Loss: 0.5672, Training Accuracy: 74.20%\n",
    "    Epoch 16/50, Test Loss: 0.5805, Test Accuracy: 72.75%\n",
    "    Epoch 17/50, Training Loss: 0.5589, Training Accuracy: 74.90%\n",
    "    Epoch 17/50, Test Loss: 0.6141, Test Accuracy: 70.50%\n",
    "    Epoch 18/50, Training Loss: 0.5776, Training Accuracy: 73.80%\n",
    "    Epoch 18/50, Test Loss: 0.6029, Test Accuracy: 70.00%\n",
    "    Epoch 19/50, Training Loss: 0.5746, Training Accuracy: 73.60%\n",
    "    Epoch 19/50, Test Loss: 0.5800, Test Accuracy: 73.50%\n",
    "    Epoch 20/50, Training Loss: 0.5756, Training Accuracy: 73.90%\n",
    "    Epoch 20/50, Test Loss: 0.5792, Test Accuracy: 73.25%\n",
    "    Epoch 21/50, Training Loss: 0.5561, Training Accuracy: 76.00%\n",
    "    Epoch 21/50, Test Loss: 0.6012, Test Accuracy: 70.00%\n",
    "    Epoch 22/50, Training Loss: 0.5643, Training Accuracy: 74.60%\n",
    "    Epoch 22/50, Test Loss: 0.5641, Test Accuracy: 75.00%\n",
    "    Epoch 23/50, Training Loss: 0.5527, Training Accuracy: 77.20%\n",
    "    Epoch 23/50, Test Loss: 0.6027, Test Accuracy: 70.00%\n",
    "    Epoch 24/50, Training Loss: 0.5652, Training Accuracy: 75.30%\n",
    "    Epoch 24/50, Test Loss: 0.5641, Test Accuracy: 76.00%\n",
    "    Epoch 25/50, Training Loss: 0.5320, Training Accuracy: 79.80%\n",
    "    Epoch 25/50, Test Loss: 0.6259, Test Accuracy: 69.25%\n",
    "    Epoch 26/50, Training Loss: 0.5503, Training Accuracy: 77.50%\n",
    "    Epoch 26/50, Test Loss: 0.6041, Test Accuracy: 70.00%\n",
    "    Epoch 27/50, Training Loss: 0.5523, Training Accuracy: 78.70%\n",
    "    Epoch 27/50, Test Loss: 0.5785, Test Accuracy: 74.00%\n",
    "    Epoch 28/50, Training Loss: 0.5410, Training Accuracy: 79.70%\n",
    "    Epoch 28/50, Test Loss: 0.6024, Test Accuracy: 72.25%\n",
    "    Epoch 29/50, Training Loss: 0.5496, Training Accuracy: 77.80%\n",
    "    Epoch 29/50, Test Loss: 0.6040, Test Accuracy: 70.50%\n",
    "    Epoch 30/50, Training Loss: 0.5495, Training Accuracy: 77.50%\n",
    "    Epoch 30/50, Test Loss: 0.5893, Test Accuracy: 71.25%\n",
    "    Epoch 31/50, Training Loss: 0.5339, Training Accuracy: 80.00%\n",
    "    Epoch 31/50, Test Loss: 0.5750, Test Accuracy: 74.25%\n",
    "    Epoch 32/50, Training Loss: 0.5465, Training Accuracy: 78.70%\n",
    "    Epoch 32/50, Test Loss: 0.5714, Test Accuracy: 75.00%\n",
    "    Epoch 33/50, Training Loss: 0.5503, Training Accuracy: 77.70%\n",
    "    Epoch 33/50, Test Loss: 0.6066, Test Accuracy: 70.00%\n",
    "    Epoch 34/50, Training Loss: 0.5529, Training Accuracy: 75.80%\n",
    "    Epoch 34/50, Test Loss: 0.5981, Test Accuracy: 72.50%\n",
    "    Epoch 35/50, Training Loss: 0.5348, Training Accuracy: 79.20%\n",
    "    Epoch 35/50, Test Loss: 0.6024, Test Accuracy: 68.50%\n",
    "    Epoch 36/50, Training Loss: 0.5235, Training Accuracy: 81.70%\n",
    "    Epoch 36/50, Test Loss: 0.5996, Test Accuracy: 72.00%\n",
    "    Epoch 37/50, Training Loss: 0.5443, Training Accuracy: 78.70%\n",
    "    Epoch 37/50, Test Loss: 0.6026, Test Accuracy: 71.50%\n",
    "    Epoch 38/50, Training Loss: 0.5518, Training Accuracy: 77.60%\n",
    "    Epoch 38/50, Test Loss: 0.5673, Test Accuracy: 75.75%\n",
    "    Epoch 39/50, Training Loss: 0.5464, Training Accuracy: 77.90%\n",
    "    Epoch 39/50, Test Loss: 0.5883, Test Accuracy: 74.50%\n",
    "    Epoch 40/50, Training Loss: 0.5337, Training Accuracy: 79.30%\n",
    "    Epoch 40/50, Test Loss: 0.5773, Test Accuracy: 73.00%\n",
    "    Epoch 41/50, Training Loss: 0.5502, Training Accuracy: 77.20%\n",
    "    Epoch 41/50, Test Loss: 0.5856, Test Accuracy: 72.25%\n",
    "    Epoch 42/50, Training Loss: 0.5360, Training Accuracy: 79.50%\n",
    "    Epoch 42/50, Test Loss: 0.5727, Test Accuracy: 73.75%\n",
    "    Epoch 43/50, Training Loss: 0.5299, Training Accuracy: 80.00%\n",
    "    Epoch 43/50, Test Loss: 0.5732, Test Accuracy: 73.50%\n",
    "    Epoch 44/50, Training Loss: 0.5314, Training Accuracy: 80.70%\n",
    "    Epoch 44/50, Test Loss: 0.6073, Test Accuracy: 70.75%\n",
    "    Epoch 45/50, Training Loss: 0.5350, Training Accuracy: 81.30%\n",
    "    Epoch 45/50, Test Loss: 0.5803, Test Accuracy: 73.50%\n",
    "    Epoch 46/50, Training Loss: 0.5285, Training Accuracy: 82.30%\n",
    "    Epoch 46/50, Test Loss: 0.5846, Test Accuracy: 71.75%\n",
    "    Epoch 47/50, Training Loss: 0.5326, Training Accuracy: 80.40%\n",
    "    Epoch 47/50, Test Loss: 0.5836, Test Accuracy: 73.50%\n",
    "    Epoch 48/50, Training Loss: 0.5504, Training Accuracy: 78.20%\n",
    "    Epoch 48/50, Test Loss: 0.5765, Test Accuracy: 74.75%\n",
    "    Epoch 49/50, Training Loss: 0.5570, Training Accuracy: 77.50%\n",
    "    Epoch 49/50, Test Loss: 0.6557, Test Accuracy: 64.50%\n",
    "    Epoch 50/50, Training Loss: 0.5338, Training Accuracy: 80.10%\n",
    "    Epoch 50/50, Test Loss: 0.6034, Test Accuracy: 70.00%\n",
    "\n",
    "## Question 5: Audio Denoising with Spectral Processing\n",
    "\n",
    "**Objective:** Develop deep learning models for audio denoising using\n",
    "spectral-domain processing (STFT/ISTFT) and neural network-based\n",
    "filtering.\n",
    "\n",
    "**Implementation:** SpeechDenoisingDataset loads noisy/clean/noise audio\n",
    "triplets. Converts audio to spectrograms using STFT (n_fft=1024,\n",
    "hop_length=512) with librosa. Neural network processes spectrograms to\n",
    "predict clean signal. Reconstructs denoised audio via ISTFT. Evaluates\n",
    "using Signal-to-Noise Ratio (SNR) metrics and saves best model to handle\n",
    "overfitting.\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    import librosa\n",
    "    import numpy as np\n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "    import os\n",
    "\n",
    "    class SpeechDenoisingDataset(Dataset):\n",
    "        def __init__(self, noisy_folder, clean_folder, noise_folder, max_seq_length=None, pad_value=0):\n",
    "            self.noisy_folder = noisy_folder\n",
    "            self.clean_folder = clean_folder\n",
    "            self.noise_folder = noise_folder\n",
    "            self.max_seq_length = max_seq_length\n",
    "            self.pad_value = pad_value\n",
    "            self.file_paths = self._load_file_paths()\n",
    "\n",
    "        def _load_file_paths(self):\n",
    "            file_paths = []\n",
    "            for i in range(1200):  # Files from 000 to 1199\n",
    "                noisy_file = os.path.join(self.noisy_folder, f'trx{i:04d}.wav')\n",
    "                clean_file = os.path.join(self.clean_folder, f'trs{i:04d}.wav')\n",
    "                noise_file = os.path.join(self.noise_folder, f'trn{i:04d}.wav')\n",
    "                file_paths.append((noisy_file, clean_file, noise_file))\n",
    "            return file_paths\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.file_paths)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            noisy_file, clean_file, noise_file = self.file_paths[idx]\n",
    "\n",
    "            y_noisy, sr = librosa.load(noisy_file, sr=None)\n",
    "            y_clean, _ = librosa.load(clean_file, sr=None)\n",
    "            y_noise, _ = librosa.load(noise_file, sr=None)\n",
    "\n",
    "            noisy_spec = librosa.stft(y_noisy,n_fft=1024, hop_length=512, win_length=1024)\n",
    "            clean_spec = librosa.stft(y_clean,n_fft=1024, hop_length=512, win_length=1024)\n",
    "            noise_spec = librosa.stft(y_noise,n_fft=1024, hop_length=512, win_length=1024)\n",
    "\n",
    "            noisy_mag = np.abs(noisy_spec)\n",
    "            clean_mag = np.abs(clean_spec)\n",
    "            noise_mag = np.abs(noise_spec)\n",
    "\n",
    "            ibm = (clean_mag > noise_mag).astype(np.float32)\n",
    "\n",
    "            if self.max_seq_length:\n",
    "                noisy_mag = self._pad_sequence(noisy_mag, self.max_seq_length)\n",
    "                clean_mag = self._pad_sequence(clean_mag, self.max_seq_length)\n",
    "                ibm = self._pad_sequence(ibm, self.max_seq_length)\n",
    "            return torch.tensor(noisy_mag.T, dtype=torch.float32), torch.tensor(ibm.T, dtype=torch.float32)\n",
    "\n",
    "        def _pad_sequence(self, sequence, max_length):\n",
    "\n",
    "            #Pads a sequence to the max_length with the specified pad_value\n",
    "\n",
    "            seq_len = sequence.shape[1]\n",
    "            if seq_len < max_length:\n",
    "                # Pad along the time axis (axis 1)\n",
    "                padding = np.full((sequence.shape[0], max_length - seq_len), self.pad_value)\n",
    "                return np.concatenate((sequence, padding), axis=1)\n",
    "            else:\n",
    "                return sequence[:, :max_length]\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    #view the spectogram\n",
    "\n",
    "    import librosa.display\n",
    "    import matplotlib.pyplot as plt\n",
    "    file_path = './homework3/tr/trn0789.wav'\n",
    "    y, sr = librosa.load(file_path, sr=None) \n",
    "    D = librosa.stft(y, n_fft=1024, hop_length=512, win_length=1024)\n",
    "    S = np.abs(D)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(S, ref=np.max), y_axis='log', x_axis='time', sr=sr)\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Spectrogram')\n",
    "    plt.show()\n",
    "    print(\"Spectrogram dimensions:\", S.shape)\n",
    "\n",
    "    Spectrogram dimensions: (513, 70)\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "\n",
    "    class DenoisingGRU(nn.Module):\n",
    "        def __init__(self, input_dim, hidden_dim, output_dim, num_layers, dropout):\n",
    "            super(DenoisingGRU, self).__init__()\n",
    "            self.gru = nn.GRU(input_dim, hidden_dim, num_layers, \n",
    "                              batch_first=True, \n",
    "                              dropout=dropout, \n",
    "                              bidirectional=True)\n",
    "            self.layer_norm = nn.LayerNorm(hidden_dim * 2)\n",
    "            self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "            self.fc_dropout = nn.Dropout(dropout)\n",
    "\n",
    "        def forward(self, x):\n",
    "            gru_out, _ = self.gru(x)\n",
    "            gru_out = self.layer_norm(gru_out)\n",
    "            gru_out = self.fc_dropout(gru_out)\n",
    "            mask = self.fc(gru_out)\n",
    "            return torch.sigmoid(mask)\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    def compute_snr(noisy_signal, clean_signal, denoised_signal):\n",
    "        noise = noisy_signal - denoised_signal\n",
    "        signal_power = np.sum(clean_signal ** 2)\n",
    "        noise_power = np.sum(noise ** 2)\n",
    "        snr = 10 * np.log10(signal_power / noise_power)\n",
    "        return snr\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    class SpeechDenoisingValidationDataset(Dataset):\n",
    "        def __init__(self, noisy_folder, clean_folder, noise_folder, max_seq_length=None, pad_value=0):\n",
    "            self.noisy_folder = noisy_folder\n",
    "            self.clean_folder = clean_folder\n",
    "            self.noise_folder = noise_folder\n",
    "            self.max_seq_length = max_seq_length\n",
    "            self.pad_value = pad_value \n",
    "            self.file_paths = self._load_file_paths()\n",
    "        def _load_file_paths(self):\n",
    "            file_paths = []\n",
    "            for i in range(120):  # Files from 000 to 119 for validation\n",
    "                noisy_file = os.path.join(self.noisy_folder, f'vn{i:04d}.wav')\n",
    "                clean_file = os.path.join(self.clean_folder, f'vs{i:04d}.wav')\n",
    "                noise_file = os.path.join(self.noise_folder, f'vx{i:04d}.wav')\n",
    "                file_paths.append((noisy_file, clean_file, noise_file))\n",
    "            return file_paths\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.file_paths)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            noisy_file, clean_file, noise_file = self.file_paths[idx]\n",
    "            y_noisy, sr = librosa.load(noisy_file, sr=None)\n",
    "            y_clean, _ = librosa.load(clean_file, sr=None)\n",
    "            y_noise, _ = librosa.load(noise_file, sr=None)\n",
    "            noisy_spec = librosa.stft(y_noisy,n_fft=1024, hop_length=512, win_length=1024)\n",
    "            clean_spec = librosa.stft(y_clean,n_fft=1024, hop_length=512, win_length=1024)\n",
    "            noise_spec = librosa.stft(y_noise,n_fft=1024, hop_length=512, win_length=1024)\n",
    "            noisy_mag = np.abs(noisy_spec)\n",
    "            clean_mag = np.abs(clean_spec)\n",
    "            noise_mag = np.abs(noise_spec)\n",
    "            ibm = (clean_mag > noise_mag).astype(np.float32)\n",
    "            if self.max_seq_length:\n",
    "                noisy_mag = self._pad_sequence(noisy_mag, self.max_seq_length)\n",
    "                clean_mag = self._pad_sequence(clean_mag, self.max_seq_length)\n",
    "                ibm = self._pad_sequence(ibm, self.max_seq_length)\n",
    "            return torch.tensor(noisy_mag.T, dtype=torch.float32), torch.tensor(ibm.T, dtype=torch.float32)\n",
    "\n",
    "        def _pad_sequence(self, sequence, max_length):\n",
    "            seq_len = sequence.shape[1]\n",
    "            if seq_len < max_length:\n",
    "                padding = np.full((sequence.shape[0], max_length - seq_len), self.pad_value)\n",
    "                return np.concatenate((sequence, padding), axis=1)\n",
    "            else:\n",
    "                return sequence[:, :max_length]\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    val_folder = '.\\\\homework3\\\\v\\\\'\n",
    "    noisy_folder_val = val_folder\n",
    "    clean_folder_val = val_folder\n",
    "    noise_folder_val = val_folder\n",
    "    validation_dataset = SpeechDenoisingValidationDataset(noisy_folder_val, clean_folder_val, noise_folder_val, max_seq_length=150)\n",
    "    validation_loader = DataLoader(validation_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    from torch.utils.data import DataLoader\n",
    "    from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "    batch_size = 120  # Batch size for training\n",
    "    learning_rate = 0.001  # Learning rate for the optimizer\n",
    "    train_folder = '.\\\\homework3\\\\tr'\n",
    "    noisy_folder = train_folder\n",
    "    clean_folder = train_folder\n",
    "    noise_folder = train_folder\n",
    "    train_dataset = SpeechDenoisingDataset(noisy_folder, clean_folder, noise_folder, max_seq_length=150)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    # Initialize model, loss function, and optimizer\n",
    "    model = DenoisingGRU(input_dim=513, hidden_dim=128, output_dim=513, num_layers=2, dropout=0.2)\n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)  # Add L2 regularization\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=30)\n",
    "    best_val_loss = float('inf')\n",
    "    num_epochs = 20\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    # Initialize lists to track metrics\n",
    "    epoch_max_snr_list = [] \n",
    "    all_snr_values = []  \n",
    "    train_loss_list = []  \n",
    "    val_loss_list = [] \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        train_loss = 0.0\n",
    "        for batch_idx, (noisy_inputs, ibm_targets) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(noisy_inputs)\n",
    "            loss = loss_fn(outputs, ibm_targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        train_loss_list.append(avg_train_loss)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {avg_train_loss:.4f}\")\n",
    "        \n",
    "        # Validation Loop\n",
    "        model.eval() \n",
    "        val_loss = 0.0\n",
    "        max_snr_list = [] \n",
    "        with torch.no_grad():\n",
    "            for val_noisy_inputs, val_ibm_targets in validation_loader:\n",
    "                val_outputs = model(val_noisy_inputs)\n",
    "                val_loss += loss_fn(val_outputs, val_ibm_targets)\n",
    "                batch_max_snr = float('-inf') \n",
    "                for i in range(val_noisy_inputs.size(0)):\n",
    "                    noisy_signal = val_noisy_inputs[i].numpy()\n",
    "                    clean_signal = val_ibm_targets[i].numpy()\n",
    "                    recovered_signal = val_outputs[i].numpy()\n",
    "                    snr = compute_snr(noisy_signal, clean_signal, recovered_signal)\n",
    "                    all_snr_values.append(snr)  \n",
    "                    batch_max_snr = max(batch_max_snr, snr)\n",
    "                max_snr_list.append(batch_max_snr) \n",
    "        avg_val_loss = val_loss / len(validation_loader)\n",
    "        avg_max_snr = np.mean(max_snr_list)  \n",
    "        epoch_max_snr_list.append(avg_max_snr)\n",
    "        val_loss_list.append(avg_val_loss)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {avg_val_loss:.4f}, Max Avg SNR: {avg_max_snr:.4f} dB\")\n",
    "        # Save the best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), 'best_denoising_model.pth')\n",
    "\n",
    "    Epoch 1/20, Training Loss: 0.6017\n",
    "    Epoch 1/20, Validation Loss: 0.4400, Max Avg SNR: 8.2505 dB\n",
    "    Epoch 2/20, Training Loss: 0.4675\n",
    "    Epoch 2/20, Validation Loss: 0.4147, Max Avg SNR: 9.2368 dB\n",
    "    Epoch 3/20, Training Loss: 0.4148\n",
    "    Epoch 3/20, Validation Loss: 0.3998, Max Avg SNR: 10.5524 dB\n",
    "    Epoch 4/20, Training Loss: 0.3870\n",
    "    Epoch 4/20, Validation Loss: 0.4515, Max Avg SNR: 10.2967 dB\n",
    "    Epoch 5/20, Training Loss: 0.3714\n",
    "    Epoch 5/20, Validation Loss: 0.4552, Max Avg SNR: 10.5448 dB\n",
    "    Epoch 6/20, Training Loss: 0.3572\n",
    "    Epoch 6/20, Validation Loss: 0.4367, Max Avg SNR: 10.5045 dB\n",
    "    Epoch 7/20, Training Loss: 0.3489\n",
    "    Epoch 7/20, Validation Loss: 0.4099, Max Avg SNR: 10.5280 dB\n",
    "    Epoch 8/20, Training Loss: 0.3429\n",
    "    Epoch 8/20, Validation Loss: 0.4449, Max Avg SNR: 10.3200 dB\n",
    "    Epoch 9/20, Training Loss: 0.3351\n",
    "    Epoch 9/20, Validation Loss: 0.4166, Max Avg SNR: 10.4459 dB\n",
    "    Epoch 10/20, Training Loss: 0.3293\n",
    "    Epoch 10/20, Validation Loss: 0.4088, Max Avg SNR: 10.4244 dB\n",
    "    Epoch 11/20, Training Loss: 0.3252\n",
    "    Epoch 11/20, Validation Loss: 0.4121, Max Avg SNR: 10.3916 dB\n",
    "    Epoch 12/20, Training Loss: 0.3199\n",
    "    Epoch 12/20, Validation Loss: 0.3908, Max Avg SNR: 10.2997 dB\n",
    "    Epoch 13/20, Training Loss: 0.3158\n",
    "    Epoch 13/20, Validation Loss: 0.3920, Max Avg SNR: 10.2864 dB\n",
    "    Epoch 14/20, Training Loss: 0.3130\n",
    "    Epoch 14/20, Validation Loss: 0.4087, Max Avg SNR: 9.4413 dB\n",
    "    Epoch 15/20, Training Loss: 0.3135\n",
    "    Epoch 15/20, Validation Loss: 0.3807, Max Avg SNR: 10.1854 dB\n",
    "    Epoch 16/20, Training Loss: 0.3083\n",
    "    Epoch 16/20, Validation Loss: 0.3977, Max Avg SNR: 10.4265 dB\n",
    "    Epoch 17/20, Training Loss: 0.3037\n",
    "    Epoch 17/20, Validation Loss: 0.3844, Max Avg SNR: 10.0120 dB\n",
    "    Epoch 18/20, Training Loss: 0.3002\n",
    "    Epoch 18/20, Validation Loss: 0.3889, Max Avg SNR: 9.5695 dB\n",
    "    Epoch 19/20, Training Loss: 0.2977\n",
    "    Epoch 19/20, Validation Loss: 0.3830, Max Avg SNR: 9.8321 dB\n",
    "    Epoch 20/20, Training Loss: 0.2965\n",
    "    Epoch 20/20, Validation Loss: 0.3918, Max Avg SNR: 9.5528 dB\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Average Max SNR per Epoch \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    epochs = list(range(1, num_epochs + 1))\n",
    "    plt.plot(epochs, epoch_max_snr_list, marker='o', color='b', label='Average Max SNR per Epoch', linestyle='-', markersize=5)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('SNR (dB)')\n",
    "    plt.title('Average Max SNR per Epoch')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plotting All SNR Values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(all_snr_values, marker='o', color='r', label='All SNR values', linestyle='-', markersize=5)\n",
    "    plt.xlabel('Batch Index')\n",
    "    plt.ylabel('SNR (dB)')\n",
    "    plt.title('All SNR Values Across Batches')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plotting Training and Validation Loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, train_loss_list, marker='x', color='g', label='Training Loss', linestyle='-', markersize=5)\n",
    "    plt.plot(epochs, val_loss_list, marker='o', color='m', label='Validation Loss', linestyle='-', markersize=5)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "##### Note: Best model saved during training for inference to handle overfitting.\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    import os\n",
    "    import librosa\n",
    "    import torch\n",
    "    import soundfile as sf\n",
    "    def load_and_preprocess(filename):\n",
    "        y, sr = librosa.load(filename, sr=None)\n",
    "        spec = librosa.stft(y, n_fft=1024, hop_length=512, win_length=1024)\n",
    "        mag = np.abs(spec)\n",
    "        mag_tensor = torch.tensor(mag.T, dtype=torch.float32) \n",
    "        mag_tensor = mag_tensor.unsqueeze(0)  \n",
    "        return mag_tensor, sr \n",
    "    results_folder = './results'\n",
    "    os.makedirs(results_folder, exist_ok=True)\n",
    "    model.eval()\n",
    "    test_folder = './homework3/te'\n",
    "    for filename in os.listdir(test_folder):\n",
    "        if filename.endswith('.wav'):\n",
    "            filepath = os.path.join(test_folder, filename)\n",
    "            noisy_spec, sr = load_and_preprocess(filepath)\n",
    "            y, _ = librosa.load(filepath, sr=None)\n",
    "            original_spec = librosa.stft(y, n_fft=1024, hop_length=512, win_length=1024)\n",
    "            phase = np.angle(original_spec) \n",
    "            with torch.no_grad():\n",
    "                denoised_spec = model(noisy_spec)\n",
    "            denoised_mag = denoised_spec.squeeze(0).T.numpy() * np.abs(original_spec)\n",
    "\n",
    "            denoised_complex_spec = denoised_mag * np.exp(1j * phase)\n",
    "            denoised_audio = librosa.istft(denoised_complex_spec, hop_length=512, length=len(y))\n",
    "            denoised_audio = denoised_audio / np.max(np.abs(denoised_audio))\n",
    "            output_filename = os.path.join(results_folder, f\"{filename}\")\n",
    "            sf.write(output_filename, denoised_audio, sr)\n",
    "\n",
    "    print(\"All the files have been processed\")\n",
    "\n",
    "    All the files have been processed"
   ],
   "id": "14d07e87-2bbc-424b-ac08-259326dea4da"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
